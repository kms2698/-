{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>XGBoost</h1>\n",
    "<ul>\n",
    "    <li>\n",
    "        <h3>XGBoost란?</h3>\n",
    "        1. Regression과 Classification 문제 모두 해결 가능 <br/>\n",
    "        2. 여러개의 Decision Tree를 조합하여 사용하는 Ensemble 알고리즘 -> 여러개를 조합하여 결과를 뽑아내는데, 정확도가 낮은 약한 모델을 여러개 조합하는 방식이 더 정확도가 높다는 방식에 기반 <br/>\n",
    "        3. Boosting은 원리가 다른데 먼저 m1~3 모델이 있을때, m1에는 x에서 샘플링된 데이터를 넣는다. 그리고, 나온 결과중에서, 예측이 잘못된 x중의 값들에 가중치를 반영해서 다음 모델인 m2에 넣는다.  마찬가지로 y2 결과에서 예측이 잘못된 x’에 값들에 가중치를 반영해서 m3에 넣는다. \n",
    "\n",
    "그리고, 각 모델의 성능이 다르기 때문에, 각 모델에 가중치 W를 반영한다.\n",
    "        \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>파라미터</h1>\n",
    "<ul>\n",
    "    <li>\n",
    "        병렬처리 – num_threads / nthread (★)\n",
    "병렬처리시 처리할 쓰레드 기본값은 현재 사용가능한 쓰레드. 기본값설정 추천.\n",
    "쓰레드말고 진짜 코어수대로 설정하라는 소리가 있는데 요즘은 안그래도 무방하다. 다만 다른작업이 필요한것같으면 코어 하나는 비워줘도 좋은 선택이다.\n",
    "        <li>\n",
    "훈련량 – learning_rate / eta (★★★)\n",
    "0.05~0.1 정도로 맞추고 그 이상이면 다른 파라미터들을 튜닝할때 편. 미세한 정확도 조정을 원하면 더 작게 둬서 마른걸레를 빤다.\n",
    "한번 다른 파라미터를 고정하면 바꿀필요가 없다. 또한 쓸데없이 긴 소수점으로 튜닝하는것도 별 쓰잘데기가 없다.\n",
    "            <li>\n",
    "반복량 – num_iterations / nrounds (★★★)\n",
    "계속 나무를 반복하며 부스팅을 하는데 몇번을 할것인가이다. lgb는 기본값이 100이라 너무 적은편이다. 1000이상정도는 해주도록 한다. 너무나도 많이하면 당연히 오버피팅이 된다.\n",
    "early_stopping이 있으면 최대한 많이 줘도 (10,000~)별 상관이 없다.\n",
    "                <li>\n",
    "조기멈춤 – early_stopping_round / early_stopping_rounds(★★)\n",
    "validation셋에 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부.\n",
    "validation셋이 없으면 무용지물이다. testset은 무조건 정확도가 올라갈것이기에.\n",
    "                    <li>\n",
    "                        나무 깊이 – max_depth (★★★)\n",
    "-1로 설정하면 제한없이 분기한다. 많은 feature가 있는 경우 더더욱 높게 설정하며, 파라미터 설정시 제일 먼저 설정한다.\n",
    "default는 -1로 제한없이 분기한다.\n",
    "                        <li>\n",
    "                            잎사귀 수 – num_leaves / max_leaves (★)\n",
    "결정트리는 이진트리 형태이기 때문에, depth가 4라면 (2의 4제곱 – 1) = 15로 설정하면 그 트리가 가질수 있는 최대 잎사귀 수이다.\n",
    "최대 잎사귀수보다 작으면 규제(Regularization)으로 작동한다.\n",
    "                            <li>\n",
    "                                행 샘플링 – bagging_fraction / subsample (★★)\n",
    "Row sampling, 즉 데이터를 일부 발췌해서 다양성을 높이는 방법으로 쓴다. 민감한 옵션이므로, Column sampling과 잘 섞어서 쓴다.\n",
    "lightGBM의 GOSS옵션을 쓴다고 하면 해당 옵션을 쓰면 에러가 난다. GOSS에서 알아서 샘플링하는 과정이 있기 때문\n",
    "                                <li>\n",
    "                                    데이터 업데이트 주기 – baggin_freq / 부재 (★)\n",
    "iteration 몇번째에 해당하는 데이터를 업데이트 할것인지.\n",
    "XGBoost는 SGD를 구현하고 있기 때문에, 기본값인 1로 동작한다고 보면 된다. 영향도가 크지 않기 때문에 기본값 추천\n",
    "                                    <li>\n",
    "열 샘플링 – feature_fraction / colsample_bytree (★★)\n",
    "컬럼에 대한 샘플링을 통해 각각의 다양성을 높인다. 랜덤포레스트에 있는 기능이였으며, 보통은 정확도가 높아지는 면이 있다.\n",
    "컬럼 샘플링을 하지 않는 1이 기본값이나, 0.7~0.9 정도로 세팅하는 편이 일반적임\n",
    "                                        <li>\n",
    "                                         L1 규제 – lambda_l1 / alpha (★)\n",
    "L1 정규화를 하여 오버피팅을 막지만, 정확도에 어떻게 영향을 줄지 예측하기가 힘들어 default인 0으로 놔두는 편\n",
    "                                             <li>\n",
    "L2 규제 – lambda_l2 / lambda (★)\n",
    "L1 정규화와 마찬가지로 0으로 놔두는 편\n",
    "                                                  <li>\n",
    "히스토그램 빈 갯수 – max_bin (★)\n",
    "히스토그램은 분기를 보통 빠르게 나누기 위해 쓰이는데, 결과적으로는 규제(regularization)로도 동작하게 되므로 모델의 예측력에도 영향을 준다.\n",
    "적게 주면 빠르게 계산하고 많이 주면 느려지지만 조금더 이상적인 트리 분기를 찾는다. 기본값은 255로 그냥 놔두는 편.\n",
    "                                                       <li>\n",
    "히스토그램 카테고리 빈 갯수 – max_cat_threshold (★)\n",
    "히스토그램을 만들때 카테고리컬 변수를 최대 몇개까지 unique하게 놔둘것인가에 대한 여부. 계산 속도가 급속도로 느려짐 기본값은 32. 정말 너무 많은 카테고리가 있는것이 아니면 줄인다.\n",
    "                                                            <li>\n",
    "충돌 비율 – max_conflict_rate (★)\n",
    "Feature Bundling실행시 충돌을 허용하는 비율을 얼마나 풀어줄지. default는 0이지만, 1미만까지 조정가능하다. 논문에서 강조한것과 다르게, lightGBM에서는 값 조정에 따른 큰 차이가 보이지 않는다.\n",
    "                                                                 <li>\n",
    "샘플 스케일링 – scale_pos_weight (★★)\n",
    "양성인 경우 이를 뻥튀기해준다. 불균형셋에서 유용할수 있으나 너무 많은 weight를 주는것은 오히려 정확도가 떨어진다. 기본값은 1이며 불균형이 얼마나 심한지에 따라 다르다. 1.1~1.5정도의 가벼운 조정은 경험상 괜춘.\n",
    "나빠지든 좋아지든 정확도에는 상당한 영향을 미치므로, 적어도 불균형셋에 대해서는 시도해보고 변화량을 보는걸 추천   \n",
    "                                                                     <li>\n",
    "                                                                         불균형 셋 조정 – is_unbalance (★)\n",
    "마찬가지로 불균형 셋이라면 이 둘의 비율을 맞춰준다. 다만, 데이터 분포가 확연하게 달라지므로 정확도에서 떨어지는 경우가 많게 되므로 SMOTE등을 고려해보자.\n",
    "                                                                         <li>\n",
    "평균에서 부스팅 – boost_from_average (★)\n",
    "평균값에서 시작으로, 속도를 빠르게 한다.\n",
    "                                                                             <li>\n",
    "피처 번들링 – enable_bundle / enable_feature_grouping (★)\n",
    "피처 번들링에 대한 여부. 보통은 라벨인코딩을 직접해주고 피처 번들링 기능을 끄는것이 희한한 결과를 보지 않는 방법 중 하나다.\n",
    "                                                                                 <li>\n",
    "부스팅 방법 – boosting / booster (★★★)\n",
    "XGBoost에서는 gblinear / gbtree / dart 지원\n",
    "lightGBM에서는 rf (랜덤포레스트) / gbdt (Gradient Boosted Decision Trees) / dart (드랍아웃 Regression Trees) / goss (Gradient-based One-Side Sampling)을 쓴다.\n",
    "기본적인 이론적 이해가 있은 뒤에 boosting을 고른다. 기본값은 gbdt로 대부분 쓰이며, 정확도가 중요할때는 딥러닝 드랍아웃과 같은 dart적용, 그리고 논문에서 강조한 샘플링을 이용한 goss 를 적용가능하다.\n",
    "GOSS는 계산속도를 상당히 줄여주지만 약간의 예측력 손상(혹은 규제로 작용)이 있을 수 있다.\n",
    "DART는 일반적인 경우 조금 더 나은 예측력을 보여주지만, 절대적인건 아니다. <li>\n",
    "    트리 빌딩 방법 – tree_method (XGBOOST에만 있음) (★)\n",
    "속도에 지대한 영향을 미치는 분기 포인트 잡을때의 히스토그램의 사용 여부이다. auto, exact, approx, hist가 있으며, hist가 제일 빠르나 exact가 일반적으로 예측력은 미세하게 높다.\n",
    "sketch_eps 라는 파라미터도 XGBOOST에만 있는데, 이는 빠르게 분기를 나누기 위해 e값을 조정하는데, 얘가 커질수록 빈은 줄어들어 속도는 빨라지지만 예측력은 내려간다. <li>\n",
    "드랍아웃 비율 – drop_rate / rate_drop (DART에만 해당) (★)\n",
    "한 주기당 떨어뜨리는 나무의 비율. 이외에도 Max Drop / Tree Uniform Drop / Tree Normalization / Tree One Drop이 있다.<li>\n",
    "XGBoost Dart 모드 – xgboost_dart_mode (★)\n",
    "GOSS에서 lr / (1 + 드랍된 트리갯수) 로 훈련량을 조절하게끔하며, 기본값은 false이다.<li>\n",
    "고 그라디언트 샘플링 – top_rate (★)\n",
    "lightGBM의 핵심인 GOSS에서 고 그라디언트를 가지는 데이터의 샘플링 비율. 즉 그래디언트순으로 정렬을 했을때 그중 100% 사용할 상위 %의 비율. 논문에서의 a다. 0.2가 기본값이다.<li>\n",
    "저 그라디언트 샘플링 – other_rate (★)\n",
    "lightGBM의 핵심인 GOSS에서 저 그라디언트를 가지는 데이터의 샘플링 비율. 전체 데이터 대비 비율이다. 기본은 0.1로 되어있으며, 논문에서의 b다.\n",
    "기본값으로 더한 a+b는 0.2+0.1 = 0.3이며, 이는 전체 데이터의 30%를 뜻한다.<li>\n",
    "트리 학습기 – tree_learner / updater (★)\n",
    "GPU를 사용할것인가에 대한 여부. 기본값은 CPU이다. 생각보다 딥러닝과 다르게 GPU를 씀으로써 얻는 이득이 상대적으로 적다.\n",
    "단순히 계산만 GPU를 해서 속도를 부스팅하는게 아니라, 몇가지 구성이 바뀌어 퍼포먼스가 좀 다르며 (CPU 우세) 속도가 가시적으로 빨라지기가 힘든데 세팅은 더 힘들다는 제보가 있다.\n",
    "적은 깊이 (depth)를 가져야 GPU가 유리하다고 한다.<li>\n",
    "Metric / Loss 관련 파라미터 (★★★)\n",
    "당연히, 학습하려는 목적에 따라 다음의 metric을 설정하여야 하며, lightGBM에서 제공하는 파라미터는 다음과 같다.\n",
    "binary(Cross Entropy)\n",
    "multiclass(Cross Entropy)\n",
    "regression_l2(MSE)\n",
    "regression_l1 (MAE)\n",
    "mape (MAPE)\n",
    "poisson (Log Transformation)\n",
    "quantile (Quantile)\n",
    "huber (Huber loss, MAE approx)\n",
    "fair (Fair loss, MAE approx)\n",
    "gamma (Residual Deviance)\n",
    "lambdarank\n",
    "tweedie\n",
    "적당한 파라미터를 찾는것은 중요하다. 다만 시간을 너무 쏟을 필요는 없다. 생각보다 크리티컬한 파라미터는 몇개 없기 때문에, depth / iteration / sample 등의 별 세개의 중요도를 가진 파라미터를 먼저 고치고, 그 이후에 별 두개를 위주로 조금씩 튜닝을 시도하면 될듯으로 보이면서 마친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "\n",
    "\n",
    "\n",
    "df_over = pd.read_csv('./csv/preprocessed/data_preprocessed_over.csv')\n",
    "df_under = pd.read_csv('./csv/preprocessed/data_preprocessed_under.csv')\n",
    "df = pd.read_csv('./csv/preprocessed/data_preprocessed_binary.csv')\n",
    "\n",
    "df_x = df.loc[:,df.columns != '식전혈당']\n",
    "df_under['식전혈당'] = df_under['식전혈당'].apply(lambda x: 0 if x <=1 else 1)\n",
    "df_over_x = df_over.loc[:,df.columns != '식전혈당']\n",
    "df_under_x = df_under.loc[:,df.columns != '식전혈당']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x.values,df[\"식전혈당\"], test_size=0.25, random_state=12)\n",
    "\n",
    "xgbr = XGBRegressor(n_estimators=100)\n",
    "xgbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = xgbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['연령대코드', '요단백', '복부비만', '음주여부', '허리둘레']\n"
     ]
    }
   ],
   "source": [
    "f = []\n",
    "# f_under = []\n",
    "for i in range(len(importance)):\n",
    "    f.append((df_x.columns[i],importance[i]))\n",
    "\n",
    "\n",
    "new_list = sorted(f, key=lambda x: x[1],reverse=True)\n",
    "important_features = list(map(lambda x: x[0],new_list))[:5]\n",
    "\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_x[important_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features.values, df[\"식전혈당\"].values, test_size=0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:48:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=8,\n",
       "             param_grid={'lambda': [1, 2, 3], 'max_depth': [3, 5, 7],\n",
       "                         'subsample': [0.6, 0.8, 1.0]},\n",
       "             return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost 분류기 생성\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# 초모수 격자생성\n",
    "xgb_param_grid = {'max_depth': [3,5,7], \n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "                  'lambda': [1,2,3]\n",
    "                 }\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "hr_grid = GridSearchCV(estimator=xgb_clf,\n",
    "                       param_grid=xgb_param_grid,\n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=8,\n",
    "                       cv=5,\n",
    "                       refit=True, \n",
    "                       return_train_score=True)\n",
    "\n",
    "hr_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65    184770\n",
      "           1       0.65      0.76      0.70    185082\n",
      "\n",
      "    accuracy                           0.68    369852\n",
      "   macro avg       0.68      0.68      0.68    369852\n",
      "weighted avg       0.68      0.68      0.68    369852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "hr_pred = hr_grid.predict(X_test)\n",
    "print(classification_report(y_test, hr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743128</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 3, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743376</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 3, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.743215</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 3, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.743838</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 5, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.743839</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 5, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.743905</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 5, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.743632</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 7, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.743697</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 7, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.743835</td>\n",
       "      <td>{'lambda': 1, 'max_depth': 7, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.743315</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 3, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.743210</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 3, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.743152</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 3, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.743815</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 5, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.743863</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 5, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.743936</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 5, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.743617</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 7, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.743714</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 7, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.743859</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 7, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.743168</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 3, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.743350</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 3, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.743375</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 3, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.743792</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 5, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.743870</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 5, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.743925</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 5, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.743696</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 7, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.743754</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 7, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.743871</td>\n",
       "      <td>{'lambda': 3, 'max_depth': 7, 'subsample': 1.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score                                           params\n",
       "0          0.743128  {'lambda': 1, 'max_depth': 3, 'subsample': 0.6}\n",
       "1          0.743376  {'lambda': 1, 'max_depth': 3, 'subsample': 0.8}\n",
       "2          0.743215  {'lambda': 1, 'max_depth': 3, 'subsample': 1.0}\n",
       "3          0.743838  {'lambda': 1, 'max_depth': 5, 'subsample': 0.6}\n",
       "4          0.743839  {'lambda': 1, 'max_depth': 5, 'subsample': 0.8}\n",
       "5          0.743905  {'lambda': 1, 'max_depth': 5, 'subsample': 1.0}\n",
       "6          0.743632  {'lambda': 1, 'max_depth': 7, 'subsample': 0.6}\n",
       "7          0.743697  {'lambda': 1, 'max_depth': 7, 'subsample': 0.8}\n",
       "8          0.743835  {'lambda': 1, 'max_depth': 7, 'subsample': 1.0}\n",
       "9          0.743315  {'lambda': 2, 'max_depth': 3, 'subsample': 0.6}\n",
       "10         0.743210  {'lambda': 2, 'max_depth': 3, 'subsample': 0.8}\n",
       "11         0.743152  {'lambda': 2, 'max_depth': 3, 'subsample': 1.0}\n",
       "12         0.743815  {'lambda': 2, 'max_depth': 5, 'subsample': 0.6}\n",
       "13         0.743863  {'lambda': 2, 'max_depth': 5, 'subsample': 0.8}\n",
       "14         0.743936  {'lambda': 2, 'max_depth': 5, 'subsample': 1.0}\n",
       "15         0.743617  {'lambda': 2, 'max_depth': 7, 'subsample': 0.6}\n",
       "16         0.743714  {'lambda': 2, 'max_depth': 7, 'subsample': 0.8}\n",
       "17         0.743859  {'lambda': 2, 'max_depth': 7, 'subsample': 1.0}\n",
       "18         0.743168  {'lambda': 3, 'max_depth': 3, 'subsample': 0.6}\n",
       "19         0.743350  {'lambda': 3, 'max_depth': 3, 'subsample': 0.8}\n",
       "20         0.743375  {'lambda': 3, 'max_depth': 3, 'subsample': 1.0}\n",
       "21         0.743792  {'lambda': 3, 'max_depth': 5, 'subsample': 0.6}\n",
       "22         0.743870  {'lambda': 3, 'max_depth': 5, 'subsample': 0.8}\n",
       "23         0.743925  {'lambda': 3, 'max_depth': 5, 'subsample': 1.0}\n",
       "24         0.743696  {'lambda': 3, 'max_depth': 7, 'subsample': 0.6}\n",
       "25         0.743754  {'lambda': 3, 'max_depth': 7, 'subsample': 0.8}\n",
       "26         0.743871  {'lambda': 3, 'max_depth': 7, 'subsample': 1.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_grid_df = pd.DataFrame(hr_grid.cv_results_)\n",
    "hr_grid_df.loc[:, ['mean_test_score', \"params\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lambda</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>92.24067</td>\n",
       "      <td>2.475009</td>\n",
       "      <td>0.542628</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lambda': 2, 'max_depth': 5, 'subsample': 1.0}</td>\n",
       "      <td>0.744289</td>\n",
       "      <td>0.743441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743936</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744707</td>\n",
       "      <td>0.744858</td>\n",
       "      <td>0.744997</td>\n",
       "      <td>0.744722</td>\n",
       "      <td>0.744515</td>\n",
       "      <td>0.74476</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lambda  \\\n",
       "14       92.24067      2.475009         0.542628        0.039759            2   \n",
       "\n",
       "   param_max_depth param_subsample  \\\n",
       "14               5               1   \n",
       "\n",
       "                                             params  split0_test_score  \\\n",
       "14  {'lambda': 2, 'max_depth': 5, 'subsample': 1.0}           0.744289   \n",
       "\n",
       "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "14           0.743441  ...         0.743936        0.000581                1   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "14            0.744707            0.744858            0.744997   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "14            0.744722            0.744515           0.74476         0.000161  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_grid_df[hr_grid_df['rank_test_score'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측모형성능(AUC):  \t 0.744\n",
      "        인덱스:           \t 14\n",
      "        max_depth:      \t 5\n",
      "        subsample:      \t 1.0\n"
     ]
    }
   ],
   "source": [
    "## 최고성능\n",
    "best_score = hr_grid.best_score_\n",
    "# 최고성능을 내는 행을 찾아냄\n",
    "best_row = hr_grid.best_index_\n",
    "\n",
    "# 최적 초모수: max_depth, subsample\n",
    "best_max_depth     = hr_grid.best_params_[\"max_depth\"]\n",
    "best_max_subsample = hr_grid.best_params_[\"subsample\"]\n",
    "\n",
    "nl = '\\n'\n",
    "print(f'예측모형성능(AUC):  \\t {best_score:.3f}{nl}\\\n",
    "        인덱스:           \\t {best_row}{nl}\\\n",
    "        max_depth:      \\t {best_max_depth}{nl}\\\n",
    "        subsample:      \\t {best_max_subsample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 5,\n",
    "#     'eta' : 0.08,\n",
    "    'subsmaple' : 1.0,\n",
    "    'objective' : 'binary:logistic',\n",
    "    'eval_metric' : 'auc',\n",
    "    'early_stoppings' : 100,\n",
    "    'labmda': 2\n",
    "}\n",
    "num_rounds = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:07:19] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { early_stoppings, labmda, subsmaple } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.72580\teval-auc:0.72554\n",
      "[1]\ttrain-auc:0.73054\teval-auc:0.73059\n",
      "[2]\ttrain-auc:0.73309\teval-auc:0.73304\n",
      "[3]\ttrain-auc:0.73608\teval-auc:0.73611\n",
      "[4]\ttrain-auc:0.73695\teval-auc:0.73695\n",
      "[5]\ttrain-auc:0.73758\teval-auc:0.73757\n",
      "[6]\ttrain-auc:0.73818\teval-auc:0.73823\n",
      "[7]\ttrain-auc:0.73847\teval-auc:0.73845\n",
      "[8]\ttrain-auc:0.73899\teval-auc:0.73896\n",
      "[9]\ttrain-auc:0.73935\teval-auc:0.73930\n",
      "[10]\ttrain-auc:0.73954\teval-auc:0.73948\n",
      "[11]\ttrain-auc:0.73982\teval-auc:0.73974\n",
      "[12]\ttrain-auc:0.74032\teval-auc:0.74022\n",
      "[13]\ttrain-auc:0.74039\teval-auc:0.74028\n",
      "[14]\ttrain-auc:0.74042\teval-auc:0.74031\n",
      "[15]\ttrain-auc:0.74065\teval-auc:0.74053\n",
      "[16]\ttrain-auc:0.74160\teval-auc:0.74141\n",
      "[17]\ttrain-auc:0.74165\teval-auc:0.74146\n",
      "[18]\ttrain-auc:0.74262\teval-auc:0.74238\n",
      "[19]\ttrain-auc:0.74273\teval-auc:0.74250\n",
      "[20]\ttrain-auc:0.74316\teval-auc:0.74291\n",
      "[21]\ttrain-auc:0.74319\teval-auc:0.74292\n",
      "[22]\ttrain-auc:0.74322\teval-auc:0.74294\n",
      "[23]\ttrain-auc:0.74327\teval-auc:0.74296\n",
      "[24]\ttrain-auc:0.74329\teval-auc:0.74297\n",
      "[25]\ttrain-auc:0.74331\teval-auc:0.74298\n",
      "[26]\ttrain-auc:0.74342\teval-auc:0.74309\n",
      "[27]\ttrain-auc:0.74343\teval-auc:0.74309\n",
      "[28]\ttrain-auc:0.74345\teval-auc:0.74311\n",
      "[29]\ttrain-auc:0.74360\teval-auc:0.74325\n",
      "[30]\ttrain-auc:0.74380\teval-auc:0.74346\n",
      "[31]\ttrain-auc:0.74381\teval-auc:0.74345\n",
      "[32]\ttrain-auc:0.74384\teval-auc:0.74346\n",
      "[33]\ttrain-auc:0.74385\teval-auc:0.74346\n",
      "[34]\ttrain-auc:0.74386\teval-auc:0.74347\n",
      "[35]\ttrain-auc:0.74404\teval-auc:0.74365\n",
      "[36]\ttrain-auc:0.74408\teval-auc:0.74368\n",
      "[37]\ttrain-auc:0.74411\teval-auc:0.74370\n",
      "[38]\ttrain-auc:0.74411\teval-auc:0.74370\n",
      "[39]\ttrain-auc:0.74417\teval-auc:0.74375\n",
      "[40]\ttrain-auc:0.74418\teval-auc:0.74374\n",
      "[41]\ttrain-auc:0.74419\teval-auc:0.74374\n",
      "[42]\ttrain-auc:0.74423\teval-auc:0.74381\n",
      "[43]\ttrain-auc:0.74424\teval-auc:0.74381\n",
      "[44]\ttrain-auc:0.74424\teval-auc:0.74380\n",
      "[45]\ttrain-auc:0.74426\teval-auc:0.74382\n",
      "[46]\ttrain-auc:0.74427\teval-auc:0.74382\n",
      "[47]\ttrain-auc:0.74428\teval-auc:0.74383\n",
      "[48]\ttrain-auc:0.74429\teval-auc:0.74383\n",
      "[49]\ttrain-auc:0.74429\teval-auc:0.74383\n",
      "[50]\ttrain-auc:0.74433\teval-auc:0.74386\n",
      "[51]\ttrain-auc:0.74436\teval-auc:0.74388\n",
      "[52]\ttrain-auc:0.74437\teval-auc:0.74388\n",
      "[53]\ttrain-auc:0.74438\teval-auc:0.74389\n",
      "[54]\ttrain-auc:0.74438\teval-auc:0.74388\n",
      "[55]\ttrain-auc:0.74439\teval-auc:0.74388\n",
      "[56]\ttrain-auc:0.74439\teval-auc:0.74387\n",
      "[57]\ttrain-auc:0.74440\teval-auc:0.74387\n",
      "[58]\ttrain-auc:0.74442\teval-auc:0.74389\n",
      "[59]\ttrain-auc:0.74443\teval-auc:0.74389\n",
      "[60]\ttrain-auc:0.74443\teval-auc:0.74390\n",
      "[61]\ttrain-auc:0.74443\teval-auc:0.74390\n",
      "[62]\ttrain-auc:0.74444\teval-auc:0.74389\n",
      "[63]\ttrain-auc:0.74446\teval-auc:0.74390\n",
      "[64]\ttrain-auc:0.74446\teval-auc:0.74390\n",
      "[65]\ttrain-auc:0.74447\teval-auc:0.74390\n",
      "[66]\ttrain-auc:0.74448\teval-auc:0.74391\n",
      "[67]\ttrain-auc:0.74449\teval-auc:0.74391\n",
      "[68]\ttrain-auc:0.74450\teval-auc:0.74391\n",
      "[69]\ttrain-auc:0.74450\teval-auc:0.74391\n",
      "[70]\ttrain-auc:0.74450\teval-auc:0.74391\n",
      "[71]\ttrain-auc:0.74451\teval-auc:0.74391\n",
      "[72]\ttrain-auc:0.74451\teval-auc:0.74391\n",
      "[73]\ttrain-auc:0.74452\teval-auc:0.74391\n",
      "[74]\ttrain-auc:0.74454\teval-auc:0.74392\n",
      "[75]\ttrain-auc:0.74455\teval-auc:0.74393\n",
      "[76]\ttrain-auc:0.74456\teval-auc:0.74393\n",
      "[77]\ttrain-auc:0.74457\teval-auc:0.74393\n",
      "[78]\ttrain-auc:0.74457\teval-auc:0.74392\n",
      "[79]\ttrain-auc:0.74457\teval-auc:0.74392\n",
      "[80]\ttrain-auc:0.74458\teval-auc:0.74392\n",
      "[81]\ttrain-auc:0.74459\teval-auc:0.74394\n",
      "[82]\ttrain-auc:0.74461\teval-auc:0.74396\n",
      "[83]\ttrain-auc:0.74461\teval-auc:0.74396\n",
      "[84]\ttrain-auc:0.74462\teval-auc:0.74396\n",
      "[85]\ttrain-auc:0.74464\teval-auc:0.74396\n",
      "[86]\ttrain-auc:0.74465\teval-auc:0.74398\n",
      "[87]\ttrain-auc:0.74465\teval-auc:0.74397\n",
      "[88]\ttrain-auc:0.74465\teval-auc:0.74397\n",
      "[89]\ttrain-auc:0.74465\teval-auc:0.74397\n",
      "[90]\ttrain-auc:0.74466\teval-auc:0.74397\n",
      "[91]\ttrain-auc:0.74467\teval-auc:0.74397\n",
      "[92]\ttrain-auc:0.74467\teval-auc:0.74397\n",
      "[93]\ttrain-auc:0.74467\teval-auc:0.74397\n",
      "[94]\ttrain-auc:0.74467\teval-auc:0.74398\n",
      "[95]\ttrain-auc:0.74469\teval-auc:0.74399\n",
      "[96]\ttrain-auc:0.74469\teval-auc:0.74399\n",
      "[97]\ttrain-auc:0.74470\teval-auc:0.74399\n",
      "[98]\ttrain-auc:0.74470\teval-auc:0.74399\n",
      "[99]\ttrain-auc:0.74471\teval-auc:0.74399\n",
      "[100]\ttrain-auc:0.74472\teval-auc:0.74399\n",
      "[101]\ttrain-auc:0.74473\teval-auc:0.74399\n",
      "[102]\ttrain-auc:0.74473\teval-auc:0.74399\n",
      "[103]\ttrain-auc:0.74474\teval-auc:0.74399\n",
      "[104]\ttrain-auc:0.74474\teval-auc:0.74399\n",
      "[105]\ttrain-auc:0.74474\teval-auc:0.74399\n",
      "[106]\ttrain-auc:0.74475\teval-auc:0.74399\n",
      "[107]\ttrain-auc:0.74476\teval-auc:0.74399\n",
      "[108]\ttrain-auc:0.74476\teval-auc:0.74399\n",
      "[109]\ttrain-auc:0.74477\teval-auc:0.74400\n",
      "[110]\ttrain-auc:0.74478\teval-auc:0.74399\n",
      "[111]\ttrain-auc:0.74479\teval-auc:0.74400\n",
      "[112]\ttrain-auc:0.74479\teval-auc:0.74400\n",
      "[113]\ttrain-auc:0.74480\teval-auc:0.74400\n",
      "[114]\ttrain-auc:0.74480\teval-auc:0.74400\n",
      "[115]\ttrain-auc:0.74480\teval-auc:0.74400\n",
      "[116]\ttrain-auc:0.74481\teval-auc:0.74401\n",
      "[117]\ttrain-auc:0.74482\teval-auc:0.74401\n",
      "[118]\ttrain-auc:0.74482\teval-auc:0.74401\n",
      "[119]\ttrain-auc:0.74482\teval-auc:0.74401\n",
      "[120]\ttrain-auc:0.74483\teval-auc:0.74401\n",
      "[121]\ttrain-auc:0.74483\teval-auc:0.74401\n",
      "[122]\ttrain-auc:0.74483\teval-auc:0.74401\n",
      "[123]\ttrain-auc:0.74483\teval-auc:0.74401\n",
      "[124]\ttrain-auc:0.74483\teval-auc:0.74401\n",
      "[125]\ttrain-auc:0.74483\teval-auc:0.74401\n",
      "[126]\ttrain-auc:0.74484\teval-auc:0.74401\n",
      "[127]\ttrain-auc:0.74484\teval-auc:0.74401\n",
      "[128]\ttrain-auc:0.74484\teval-auc:0.74401\n",
      "[129]\ttrain-auc:0.74484\teval-auc:0.74401\n",
      "[130]\ttrain-auc:0.74484\teval-auc:0.74401\n",
      "[131]\ttrain-auc:0.74485\teval-auc:0.74401\n",
      "[132]\ttrain-auc:0.74485\teval-auc:0.74401\n",
      "[133]\ttrain-auc:0.74485\teval-auc:0.74401\n",
      "[134]\ttrain-auc:0.74485\teval-auc:0.74401\n",
      "[135]\ttrain-auc:0.74486\teval-auc:0.74402\n",
      "[136]\ttrain-auc:0.74486\teval-auc:0.74401\n",
      "[137]\ttrain-auc:0.74486\teval-auc:0.74401\n",
      "[138]\ttrain-auc:0.74486\teval-auc:0.74401\n",
      "[139]\ttrain-auc:0.74487\teval-auc:0.74401\n",
      "[140]\ttrain-auc:0.74488\teval-auc:0.74401\n",
      "[141]\ttrain-auc:0.74488\teval-auc:0.74401\n",
      "[142]\ttrain-auc:0.74488\teval-auc:0.74401\n",
      "[143]\ttrain-auc:0.74489\teval-auc:0.74400\n",
      "[144]\ttrain-auc:0.74489\teval-auc:0.74400\n",
      "[145]\ttrain-auc:0.74489\teval-auc:0.74400\n",
      "[146]\ttrain-auc:0.74489\teval-auc:0.74400\n",
      "[147]\ttrain-auc:0.74489\teval-auc:0.74400\n",
      "[148]\ttrain-auc:0.74489\teval-auc:0.74401\n",
      "[149]\ttrain-auc:0.74490\teval-auc:0.74401\n",
      "[150]\ttrain-auc:0.74490\teval-auc:0.74401\n",
      "[151]\ttrain-auc:0.74490\teval-auc:0.74401\n",
      "[152]\ttrain-auc:0.74491\teval-auc:0.74401\n",
      "[153]\ttrain-auc:0.74491\teval-auc:0.74401\n",
      "[154]\ttrain-auc:0.74491\teval-auc:0.74401\n",
      "[155]\ttrain-auc:0.74491\teval-auc:0.74401\n",
      "[156]\ttrain-auc:0.74492\teval-auc:0.74400\n",
      "[157]\ttrain-auc:0.74492\teval-auc:0.74401\n",
      "[158]\ttrain-auc:0.74492\teval-auc:0.74401\n",
      "[159]\ttrain-auc:0.74492\teval-auc:0.74401\n",
      "[160]\ttrain-auc:0.74493\teval-auc:0.74401\n",
      "[161]\ttrain-auc:0.74493\teval-auc:0.74401\n",
      "[162]\ttrain-auc:0.74493\teval-auc:0.74401\n",
      "[163]\ttrain-auc:0.74493\teval-auc:0.74402\n",
      "[164]\ttrain-auc:0.74493\teval-auc:0.74402\n",
      "[165]\ttrain-auc:0.74494\teval-auc:0.74401\n",
      "[166]\ttrain-auc:0.74494\teval-auc:0.74401\n",
      "[167]\ttrain-auc:0.74494\teval-auc:0.74401\n",
      "[168]\ttrain-auc:0.74494\teval-auc:0.74401\n",
      "[169]\ttrain-auc:0.74495\teval-auc:0.74401\n",
      "[170]\ttrain-auc:0.74496\teval-auc:0.74403\n",
      "[171]\ttrain-auc:0.74496\teval-auc:0.74403\n",
      "[172]\ttrain-auc:0.74497\teval-auc:0.74403\n",
      "[173]\ttrain-auc:0.74497\teval-auc:0.74403\n",
      "[174]\ttrain-auc:0.74497\teval-auc:0.74403\n",
      "[175]\ttrain-auc:0.74497\teval-auc:0.74402\n",
      "[176]\ttrain-auc:0.74497\teval-auc:0.74402\n",
      "[177]\ttrain-auc:0.74497\teval-auc:0.74402\n",
      "[178]\ttrain-auc:0.74498\teval-auc:0.74403\n",
      "[179]\ttrain-auc:0.74498\teval-auc:0.74403\n",
      "[180]\ttrain-auc:0.74499\teval-auc:0.74403\n",
      "[181]\ttrain-auc:0.74499\teval-auc:0.74403\n",
      "[182]\ttrain-auc:0.74499\teval-auc:0.74403\n",
      "[183]\ttrain-auc:0.74499\teval-auc:0.74403\n",
      "[184]\ttrain-auc:0.74499\teval-auc:0.74403\n",
      "[185]\ttrain-auc:0.74499\teval-auc:0.74403\n",
      "[186]\ttrain-auc:0.74500\teval-auc:0.74403\n",
      "[187]\ttrain-auc:0.74500\teval-auc:0.74403\n",
      "[188]\ttrain-auc:0.74501\teval-auc:0.74403\n",
      "[189]\ttrain-auc:0.74501\teval-auc:0.74404\n",
      "[190]\ttrain-auc:0.74502\teval-auc:0.74404\n",
      "[191]\ttrain-auc:0.74502\teval-auc:0.74404\n",
      "[192]\ttrain-auc:0.74503\teval-auc:0.74404\n",
      "[193]\ttrain-auc:0.74503\teval-auc:0.74404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194]\ttrain-auc:0.74504\teval-auc:0.74403\n",
      "[195]\ttrain-auc:0.74504\teval-auc:0.74403\n",
      "[196]\ttrain-auc:0.74504\teval-auc:0.74403\n",
      "[197]\ttrain-auc:0.74505\teval-auc:0.74404\n",
      "[198]\ttrain-auc:0.74505\teval-auc:0.74404\n",
      "[199]\ttrain-auc:0.74506\teval-auc:0.74404\n",
      "[200]\ttrain-auc:0.74506\teval-auc:0.74403\n",
      "[201]\ttrain-auc:0.74506\teval-auc:0.74403\n",
      "[202]\ttrain-auc:0.74506\teval-auc:0.74403\n",
      "[203]\ttrain-auc:0.74506\teval-auc:0.74403\n",
      "[204]\ttrain-auc:0.74506\teval-auc:0.74403\n",
      "[205]\ttrain-auc:0.74506\teval-auc:0.74403\n",
      "[206]\ttrain-auc:0.74507\teval-auc:0.74403\n",
      "[207]\ttrain-auc:0.74507\teval-auc:0.74403\n",
      "[208]\ttrain-auc:0.74507\teval-auc:0.74403\n",
      "[209]\ttrain-auc:0.74507\teval-auc:0.74403\n",
      "[210]\ttrain-auc:0.74508\teval-auc:0.74402\n",
      "[211]\ttrain-auc:0.74508\teval-auc:0.74403\n",
      "[212]\ttrain-auc:0.74508\teval-auc:0.74403\n",
      "[213]\ttrain-auc:0.74508\teval-auc:0.74403\n",
      "[214]\ttrain-auc:0.74508\teval-auc:0.74403\n",
      "[215]\ttrain-auc:0.74508\teval-auc:0.74403\n",
      "[216]\ttrain-auc:0.74508\teval-auc:0.74403\n",
      "[217]\ttrain-auc:0.74508\teval-auc:0.74403\n",
      "[218]\ttrain-auc:0.74509\teval-auc:0.74403\n",
      "[219]\ttrain-auc:0.74509\teval-auc:0.74403\n",
      "[220]\ttrain-auc:0.74509\teval-auc:0.74403\n",
      "[221]\ttrain-auc:0.74509\teval-auc:0.74403\n",
      "[222]\ttrain-auc:0.74509\teval-auc:0.74403\n",
      "[223]\ttrain-auc:0.74509\teval-auc:0.74403\n",
      "[224]\ttrain-auc:0.74510\teval-auc:0.74403\n",
      "[225]\ttrain-auc:0.74510\teval-auc:0.74403\n",
      "[226]\ttrain-auc:0.74510\teval-auc:0.74403\n",
      "[227]\ttrain-auc:0.74510\teval-auc:0.74403\n",
      "[228]\ttrain-auc:0.74510\teval-auc:0.74403\n",
      "[229]\ttrain-auc:0.74510\teval-auc:0.74403\n",
      "[230]\ttrain-auc:0.74510\teval-auc:0.74403\n",
      "[231]\ttrain-auc:0.74511\teval-auc:0.74403\n",
      "[232]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[233]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[234]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[235]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[236]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[237]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[238]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[239]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[240]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[241]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[242]\ttrain-auc:0.74511\teval-auc:0.74402\n",
      "[243]\ttrain-auc:0.74511\teval-auc:0.74401\n",
      "[244]\ttrain-auc:0.74512\teval-auc:0.74402\n",
      "[245]\ttrain-auc:0.74512\teval-auc:0.74402\n",
      "[246]\ttrain-auc:0.74512\teval-auc:0.74402\n",
      "[247]\ttrain-auc:0.74513\teval-auc:0.74402\n",
      "[248]\ttrain-auc:0.74513\teval-auc:0.74402\n",
      "[249]\ttrain-auc:0.74513\teval-auc:0.74402\n",
      "[250]\ttrain-auc:0.74513\teval-auc:0.74402\n",
      "[251]\ttrain-auc:0.74513\teval-auc:0.74402\n",
      "[252]\ttrain-auc:0.74513\teval-auc:0.74402\n",
      "[253]\ttrain-auc:0.74513\teval-auc:0.74402\n",
      "[254]\ttrain-auc:0.74514\teval-auc:0.74403\n",
      "[255]\ttrain-auc:0.74514\teval-auc:0.74403\n",
      "[256]\ttrain-auc:0.74514\teval-auc:0.74403\n",
      "[257]\ttrain-auc:0.74514\teval-auc:0.74403\n",
      "[258]\ttrain-auc:0.74514\teval-auc:0.74403\n",
      "[259]\ttrain-auc:0.74514\teval-auc:0.74403\n",
      "[260]\ttrain-auc:0.74514\teval-auc:0.74403\n",
      "[261]\ttrain-auc:0.74515\teval-auc:0.74403\n",
      "[262]\ttrain-auc:0.74515\teval-auc:0.74403\n",
      "[263]\ttrain-auc:0.74516\teval-auc:0.74403\n",
      "[264]\ttrain-auc:0.74516\teval-auc:0.74403\n",
      "[265]\ttrain-auc:0.74516\teval-auc:0.74403\n",
      "[266]\ttrain-auc:0.74517\teval-auc:0.74403\n",
      "[267]\ttrain-auc:0.74517\teval-auc:0.74403\n",
      "[268]\ttrain-auc:0.74517\teval-auc:0.74403\n",
      "[269]\ttrain-auc:0.74517\teval-auc:0.74403\n",
      "[270]\ttrain-auc:0.74517\teval-auc:0.74403\n",
      "[271]\ttrain-auc:0.74518\teval-auc:0.74403\n",
      "[272]\ttrain-auc:0.74518\teval-auc:0.74403\n",
      "[273]\ttrain-auc:0.74518\teval-auc:0.74404\n",
      "[274]\ttrain-auc:0.74519\teval-auc:0.74403\n",
      "[275]\ttrain-auc:0.74519\teval-auc:0.74404\n",
      "[276]\ttrain-auc:0.74519\teval-auc:0.74404\n",
      "[277]\ttrain-auc:0.74519\teval-auc:0.74404\n",
      "[278]\ttrain-auc:0.74519\teval-auc:0.74403\n",
      "[279]\ttrain-auc:0.74520\teval-auc:0.74403\n",
      "[280]\ttrain-auc:0.74520\teval-auc:0.74403\n",
      "[281]\ttrain-auc:0.74520\teval-auc:0.74403\n",
      "[282]\ttrain-auc:0.74520\teval-auc:0.74403\n",
      "[283]\ttrain-auc:0.74520\teval-auc:0.74403\n",
      "[284]\ttrain-auc:0.74521\teval-auc:0.74403\n",
      "[285]\ttrain-auc:0.74521\teval-auc:0.74403\n",
      "[286]\ttrain-auc:0.74521\teval-auc:0.74403\n",
      "[287]\ttrain-auc:0.74521\teval-auc:0.74403\n",
      "[288]\ttrain-auc:0.74521\teval-auc:0.74403\n",
      "[289]\ttrain-auc:0.74521\teval-auc:0.74403\n",
      "[290]\ttrain-auc:0.74521\teval-auc:0.74403\n"
     ]
    }
   ],
   "source": [
    "wlist = [(dtrain,'train'),(dtest,'eval')]\n",
    "xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = num_rounds, early_stopping_rounds=100, evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6785227604555336\n",
      "confusion_matrix [[110918, 73852], [45047, 140035]]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "\n",
    "pred = [1 if x > 0.5 else 0 for x in pred_probs]\n",
    "\n",
    "confusion_matrix = [[0,0],[0,0]]\n",
    "\n",
    "count_accuracy = 0\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == y_test[i]:\n",
    "        count_accuracy += 1\n",
    "    confusion_matrix[y_test[i]][pred[i]] += 1\n",
    "\n",
    "print('accuracy', count_accuracy / len(pred))\n",
    "print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    print('오차행렬:\\n', confusion)\n",
    "    print('\\n정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1: {:.4f}'.format(F1))\n",
    "    print('AUC: {:.4f}'.format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[110918  73852]\n",
      " [ 45047 140035]]\n",
      "\n",
      "정확도: 0.6785\n",
      "정밀도: 0.6547\n",
      "재현율: 0.7566\n",
      "F1: 0.7020\n",
      "AUC: 0.6785\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FPR, TPR, _ = roc_curve(y_test, pred_probs)\n",
    "plt.plot(FPR, TPR)\n",
    "plt.plot([0,1],[0,1],'--', color='black') # 대각선\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.725695</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.725529</td>\n",
       "      <td>0.001113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730670</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.730495</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.732982</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.732827</td>\n",
       "      <td>0.001101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.735226</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.735001</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.736715</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.736516</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.737445</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.737263</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.737881</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.737703</td>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.738419</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.738211</td>\n",
       "      <td>0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739030</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.738812</td>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.739509</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.739277</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0        0.725695       0.000280       0.725529      0.001113\n",
       "1        0.730670       0.000272       0.730495      0.001135\n",
       "2        0.732982       0.000262       0.732827      0.001101\n",
       "3        0.735226       0.001023       0.735001      0.001613\n",
       "4        0.736715       0.000629       0.736516      0.001151\n",
       "5        0.737445       0.000602       0.737263      0.001032\n",
       "6        0.737881       0.000600       0.737703      0.001045\n",
       "7        0.738419       0.000483       0.738211      0.001027\n",
       "8        0.739030       0.000350       0.738812      0.001181\n",
       "9        0.739509       0.000546       0.739277      0.001056"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_dmatrix = dtrain\n",
    "\n",
    "cv_params = {\"objective\":\"binary:logistic\", \n",
    "             \"max_depth\":5}\n",
    "\n",
    "hr_cv = xgb.cv(dtrain=hr_dmatrix, \n",
    "               params=cv_params, \n",
    "               nfold=5, \n",
    "               num_boost_round=10, \n",
    "               metrics=\"auc\", \n",
    "               as_pandas=True)\n",
    "\n",
    "hr_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=100):\n",
    "   \n",
    "#     # get new n_estimator\n",
    "#     if useTrainCV:\n",
    "#         xgb_param = alg.get_xgb_params()\n",
    "#         xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain['식전혈당'].values)\n",
    "#         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "#                           metrics='error', early_stopping_rounds=early_stopping_rounds)\n",
    "#         alg.set_params(n_estimators=cvresult.shape[0])\n",
    "#         print(alg)\n",
    "    \n",
    "#     # Fit the algorithm on the data\n",
    "#     alg.fit(dtrain[predictors], dtrain['식전혈당'], eval_metric='error')\n",
    "        \n",
    "#     #Predict training set:\n",
    "#     dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "#     dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "#     #Print model report:\n",
    "#     print(\"\\nModel Report\")\n",
    "#     print(\"Training Accuracy : %.4g\" % metrics.accuracy_score(dtrain['식전혈당'].values, dtrain_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, gamma=0, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.1, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=369, n_jobs=None, nthread=-1, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=1, seed=2019, subsample=0.8, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "\n",
      "Model Report\n",
      "Training Accuracy : 0.679\n"
     ]
    }
   ],
   "source": [
    "# from xgboost.sklearn import XGBClassifier\n",
    "# from sklearn import metrics\n",
    "\n",
    "# xgb1 = XGBClassifier(\n",
    "#     learning_rate =0.1,\n",
    "#     n_estimators=1000,\n",
    "#     max_depth=5,\n",
    "#     min_child_weight=1,\n",
    "#     gamma=0,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     objective= 'binary:logistic',\n",
    "#     nthread=-1,\n",
    "#     scale_pos_weight=1,\n",
    "#     seed=2019\n",
    "# )\n",
    "# modelfit(xgb1, df, important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "\n",
    "# param_test1 = {\n",
    "#  'max_depth':range(3,10,3),\n",
    "#  'min_child_weight':range(1,6,2)\n",
    "# }\n",
    "# gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "#                                                   n_estimators=1000, \n",
    "#                                                   max_depth=5, \n",
    "#                                                   min_child_weight=1, \n",
    "#                                                   gamma=0, \n",
    "#                                                   subsample=0.8, \n",
    "#                                                   colsample_bytree=0.8,\n",
    "#                                                   objective= 'binary:logistic', \n",
    "#                                                   nthread=-1, \n",
    "#                                                   scale_pos_weight=1, seed=2019),\n",
    "# param_grid = param_test1, scoring='accuracy',n_jobs=-1,iid=False, cv=5, verbose=10)\n",
    "# gsearch1.fit(df[important_features],df['식전혈당'])\n",
    "# gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
